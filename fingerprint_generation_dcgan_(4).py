# -*- coding: utf-8 -*-
"""Fingerprint_generation_dcgan (4).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16JZkRXOOxstLWi8G6hXYcxPHXC1z6Es-

## Connect drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""## Download Dataset from kaggle"""

! pip install kaggle
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d ruizgara/socofing

"""## Install required libraries of  torch and torchvision"""

!pip install torch
!pip install torchvision

"""### Unzip and Check the accessbility of dataset"""

!unzip socofing.zip -d /content/drive/MyDrive/fingerprintgeneration/dataset/
import os
for i in os.listdir("/content/drive/MyDrive/fingerprintgeneration/dataset/"):
    print(str(len(os.listdir("/content/drive/MyDrive/fingerprintgeneration/dataset/"+i))) +" "+ i +" Images")

"""## Importing the libraries"""

# Commented out IPython magic to ensure Python compatibility.
import os                                   # os package
import time                                 # time package
import torch                                # root package
import torch.nn as nn                       # neural networks
import torch.optim as optim                 # Optimizers e.g. gradient descent, ADAM, etc. 
import torchvision.datasets as dset         # dataset representation
from torch.utils.data import DataLoader     # dataset loading
import torchvision.transforms as transforms # composable transforms
from torchvision.utils import make_grid, save_image
from torch.autograd import Variable

# %matplotlib inline
import random                               # random package
import numpy as np                          # package for scientific computing 
import matplotlib.pyplot as plt             # visualization package
import matplotlib.image as mpimg
import matplotlib.animation as animation
import warnings                             # supress warnings
warnings.filterwarnings('ignore')
from tqdm import tqdm_notebook as tqdm      # progres package

# random seed everything
def random_seed(seed_value, use_cuda):
    np.random.seed(seed_value) # cpu vars
    torch.manual_seed(seed_value) # cpu vars
    random.seed(seed_value) # Python
    if use_cuda: 
        torch.cuda.manual_seed(seed_value)
        torch.cuda.manual_seed_all(seed_value) # gpu vars
        torch.backends.cudnn.deterministic = True  #needed
        torch.backends.cudnn.benchmark = False

random_seed(17, True)

"""## Real data visualization"""

PATH = '/content/drive/MyDrive/output/'
images = os.listdir(PATH)
print(f'There are {len(images)} Generated Finger prints.')

fig, axes = plt.subplots(nrows=10, ncols=5, figsize=(20,20))

for indx, axis in enumerate(axes.flatten()):
    rnd_indx = np.random.randint(0, len(os.listdir(PATH)))
    img = plt.imread(PATH + images[rnd_indx])
    imgplot = axis.imshow(img)
    axis.set_title(images[rnd_indx])
    axis.set_axis_off()
plt.tight_layout(rect=[0, 0.03, 1, 0.95])

"""### Image Processing (Image data aqcuistion ,  Data preprocessing , Data Transformation , Split data into train and test with labels )"""

batch_size = 32
image_size = 64

random_transforms = [transforms.ColorJitter(), transforms.RandomRotation(degrees=20)]
transform = transforms.Compose([transforms.Resize(64),
                                transforms.CenterCrop(64),
                                transforms.RandomHorizontalFlip(p=0.5),
                                transforms.RandomApply(random_transforms, p=0.2),
                                transforms.ToTensor(),
                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

train_data = dset.ImageFolder('fingerprintgeneration/dataset/fingerprintdataset/', transform=transform)
train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)
                                           
imgs, label = next(iter(train_loader))
imgs = imgs.numpy().transpose(0, 2, 3, 1)

"""### Weights
Defining the `weights_init` function
"""

def weights_init(m):
    """
    Takes as input a neural network m that will initialize all its weights.
    """
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        m.weight.data.normal_(0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        m.weight.data.normal_(1.0, 0.02)
        m.bias.data.fill_(0)

"""### Generator"""

class Generator(nn.Module):
    def __init__(self, nz=128, channels=3):
        super(Generator, self).__init__()
        
        self.nz = nz
        self.channels = channels
        
        def convlayer(n_input, n_output, k_size=4, stride=2, padding=0):
            block = [
                nn.ConvTranspose2d(n_input, n_output, kernel_size=k_size, stride=stride, padding=padding, bias=False),
                nn.BatchNorm2d(n_output),
                nn.ReLU(inplace=True),
            ]
            return block

        self.model = nn.Sequential(
            *convlayer(self.nz, 1024, 4, 1, 0), # Fully connected layer via convolution.
            *convlayer(1024, 512, 4, 2, 1),
            *convlayer(512, 256, 4, 2, 1),
            *convlayer(256, 128, 4, 2, 1),
            *convlayer(128, 64, 4, 2, 1),
            nn.ConvTranspose2d(64, self.channels, 3, 1, 1),
            nn.Tanh()
        )

    def forward(self, z):
        z = z.view(-1, self.nz, 1, 1)
        img = self.model(z)
        return img

"""### Discriminator"""

class Discriminator(nn.Module):
    def __init__(self, channels=3):
        super(Discriminator, self).__init__()
        
        self.channels = channels

        def convlayer(n_input, n_output, k_size=4, stride=2, padding=0, bn=False):
            block = [nn.Conv2d(n_input, n_output, kernel_size=k_size, stride=stride, padding=padding, bias=False)]
            if bn:
                block.append(nn.BatchNorm2d(n_output))
            block.append(nn.LeakyReLU(0.2, inplace=True))
            return block

        self.model = nn.Sequential(
            *convlayer(self.channels, 32, 4, 2, 1),
            *convlayer(32, 64, 4, 2, 1),
            *convlayer(64, 128, 4, 2, 1, bn=True),
            *convlayer(128, 256, 4, 2, 1, bn=True),
            nn.Conv2d(256, 1, 4, 1, 0, bias=False),  # FC with Conv.
        )

    def forward(self, imgs):
        logits = self.model(imgs)
        out = torch.sigmoid(logits)
    
        return out.view(-1, 1)

"""### Training

### Parameters
"""

!mkdir results

batch_size = 32
LR_G = 0.001
LR_D = 0.0005

beta1 = 0.5
epochs = 100

real_label = 0.9
fake_label = 0
nz = 128

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

"""### Initialize models and optimizers"""

netG = Generator(nz).to(device)
netD = Discriminator().to(device)

criterion = nn.BCELoss()

optimizerD = optim.Adam(netD.parameters(), lr=LR_D, betas=(beta1, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=LR_G, betas=(beta1, 0.999))

fixed_noise = torch.randn(25, nz, 1, 1, device=device)

G_losses = []
D_losses = []
epoch_time = []

"""### Plot Loss per EPOCH"""

def plot_loss (G_losses, D_losses, epoch):
    plt.figure(figsize=(10,5))
    plt.title("Generator and Discriminator Loss - EPOCH "+ str(epoch))
    plt.plot(G_losses,label="G")
    plt.plot(D_losses,label="D")
    plt.xlabel("iterations")
    plt.ylabel("Loss")
    plt.legend()
    plt.show()

"""### Show generated images"""

def show_generated_img(n_images=5):
    sample = []
    for _ in range(n_images):
        noise = torch.randn(1, nz, 1, 1, device=device)
        gen_image = netG(noise).to("cpu").clone().detach().squeeze(0)
        gen_image = gen_image.numpy().transpose(1, 2, 0)
        sample.append(gen_image)
    
    figure, axes = plt.subplots(1, len(sample), figsize = (64,64))
    for index, axis in enumerate(axes):
        axis.axis('off')
        image_array = sample[index]
        axis.imshow(image_array)
        
    plt.show()
    plt.close()

"""### Training Loop"""

# Commented out IPython magic to ensure Python compatibility.
for epoch in range(epochs):
    
    start = time.time()
    for ii, (real_images, train_labels) in tqdm(enumerate(train_loader), total=len(train_loader)):
        ############################
        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
        ###########################
        # train with real
        netD.zero_grad()
        real_images = real_images.to(device)
        batch_size = real_images.size(0)
        labels = torch.full((batch_size, 1), real_label, device=device)

        output = netD(real_images)
        errD_real = criterion(output, labels)
        errD_real.backward()
        D_x = output.mean().item()

        # train with fake
        noise = torch.randn(batch_size, nz, 1, 1, device=device)
        fake = netG(noise)
        labels.fill_(fake_label)
        output = netD(fake.detach())
        errD_fake = criterion(output, labels)
        errD_fake.backward()
        D_G_z1 = output.mean().item()
        errD = errD_real + errD_fake
        optimizerD.step()

        ############################
        # (2) Update G network: maximize log(D(G(z)))
        ###########################
        netG.zero_grad()
        labels.fill_(real_label)  # fake labels are real for generator cost
        output = netD(fake)
        errG = criterion(output, labels)
        errG.backward()
        D_G_z2 = output.mean().item()
        optimizerG.step()
        
        # Save Losses for plotting later
        G_losses.append(errG.item())
        D_losses.append(errD.item())
        
        if (ii+1) % (len(train_loader)//2) == 0:
            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'
#                   % (epoch + 1, epochs, ii+1, len(train_loader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))
            
    plot_loss (G_losses, D_losses, epoch)
    torch.save(netG.state_dict(), 'fingerprintgeneration/model/generator.pth')
    torch.save(netD.state_dict(), 'fingerprintgeneration/model/discriminator.pth')
    G_losses = []
    D_losses = []
    if epoch % 10 == 0:
        show_generated_img()

    epoch_time.append(time.time()- start)

print (">> average EPOCH duration = ", np.mean(epoch_time))

!pip install dcgan_pytorch

"""#### Generated Images"""

from torchvision.models.segmentation import deeplabv3_resnet50
import shutil

import torchvision.utils

# Load model weights.
state_dict = torch.load("/content/drive/MyDrive/model/generator.pth", map_location=device)
model = Generator()
model.load_state_dict(state_dict )
model.eval()
 # Start the verification mode of the model.
model.eval()

from torchvision.models.segmentation import deeplabv3_resnet50
import shutil

import torchvision.utils

# Load model weights.
state_dict = torch.load("/content/drive/MyDrive/model/discriminator.pth")
modeld = Discriminator()
modeld.load_state_dict(state_dict)
modeld.eval()
 # Start the verification mode of the model.
modeld.eval()
modeld

from PIL import Image
import torchvision.transforms.functional as TF
import torchvision.transforms as T
imagetest=Image.open('/content/drive/MyDrive/output/image_i_batch0.png')
imagetest = imagetest.resize((64, 64), Image.ANTIALIAS)
imagetest = TF.to_tensor(imagetest)
imagetest = imagetest.unsqueeze_(0)
netG=model
netD=modeld
batch_size = 1
gen_z = torch.randn(batch_size, nz, 1, 1, device=device)
gen_images = netG(gen_z)
images = gen_images.to("cpu").clone().detach()
    #labels = torch.full((batch_size, 1), real_label, device=device)
print(images.shape)
print(imagetest.shape)
realoutput = netD(imagetest)
fakeoutput = netD(images)
fakeoutput
errD = criterion(fakeoutput, realoutput)
errD.backward()
realD_x = realoutput.mean().item()
fakeD_x = realoutput.mean().item()
print(realoutput)
print(fakeoutput)
print(errD)
imagetest=torch.squeeze(imagetest)
images=torch.squeeze(images)
transform = T.ToPILImage()
imagetest= transform(imagetest)
fakeimagetest= transform(images)
imagetest
fakeimagetest

from PIL import Image
import torchvision.transforms.functional as TF
import torchvision.transforms as T
imagetest=Image.open('/content/drive/MyDrive/fingerprintgeneration/dataset/SOCOFing/Altered/Altered-Easy/100__M_Left_index_finger_CR.BMP')
random_transforms = [transforms.ColorJitter(), transforms.RandomRotation(degrees=20)]
transform = transforms.Compose([transforms.Resize(64),
                                transforms.CenterCrop(64),
                                transforms.RandomHorizontalFlip(p=0.5),
                                transforms.RandomApply(random_transforms, p=0.2),
                                transforms.ToTensor(),
                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
imagetest= transform(imagetest)

import os
if not os.path.exists('/content/drive/MyDrive/output'):
    os.mkdir('/content/drive/MyDrive/output')
netG=model 
im_batch_size = 50
n_images=10000

for i_batch in tqdm(range(0, n_images, im_batch_size)):
    gen_z = torch.randn(im_batch_size, nz, 1, 1, device=device)
    gen_images = netG(gen_z)
    images = gen_images.to("cpu").clone().detach()
    #images = images.numpy().transpose(0, 2, 3, 1)
    for i_image in range(gen_images.size(0)):
        save_image(gen_images[i_image, :, :, :], os.path.join('/content/drive/MyDrive/output/image_i_batch'+str(i_image)+'.png'))

fig = plt.figure(figsize=(25, 16))
# display 10 images from each class
for i, j in enumerate(images[:32]):
    # ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])
    plt.figure()
    plt.imshow(j)
    plt.show()

"""### Submission

#### Save models
"""

torch.save(netG.state_dict(), 'fingerprintgeneration/model/generator.pth')
torch.save(netD.state_dict(), 'fingerprintgeneration/model/discriminator.pth')